{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is a random variable in probability theory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B30ZDd25cNqv"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **random variable** in probability theory is a variable that assigns a numerical value to each possible outcome of a random experiment. It is a function that maps outcomes from a sample space to real numbers. There are two types: **discrete** random variables, which take on countable values (like the outcome of rolling a die), and **continuous** random variables, which can take on any value within a range (like the height of a person). Random variables are used to quantify uncertainty and to calculate probabilities, expectations, and variances in statistics and probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What are the types of random variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhgF9XTwdv5j"
   },
   "source": [
    "\n",
    "\n",
    "Ans: There are two main types of random variables:\n",
    "\n",
    "1. **Discrete Random Variable**: Takes on a countable number of distinct values. Examples include the number of heads in 3 coin tosses or the result of rolling a die. These values can be listed and often have a finite or countably infinite set.\n",
    "\n",
    "2. **Continuous Random Variable**: Takes on an infinite number of values within a given range. Examples include height, weight, or temperature. These variables are described using intervals and require probability density functions (PDFs) to find probabilities.\n",
    "\n",
    "Each type is used based on the nature of the data in a random experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the difference between discrete and continuous distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p15WoEqseJi_"
   },
   "source": [
    "\n",
    "\n",
    "Ans: Discrete and continuous distributions differ based on the type of random variable they describe.\n",
    "\n",
    "A **discrete distribution** deals with countable outcomes, like rolling a die or counting defects in a batch. It assigns probabilities to specific values using a probability mass function (PMF).\n",
    "\n",
    "A **continuous distribution** handles uncountable outcomes, such as height or temperature. It uses a probability density function (PDF), and probabilities are found over intervals, not exact values (e.g., P(1 < X < 2)).\n",
    "\n",
    "In summary, discrete = specific values with PMF; continuous = ranges with PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What are probability distribution functions (PDF)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgIj6Xqoec-T"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **Probability Distribution Function (PDF)** describes how probabilities are assigned to values of a random variable. For **discrete** variables, it’s called a **Probability Mass Function (PMF)**, which gives the probability for each exact outcome. For **continuous** variables, the PDF is a function whose integral over an interval gives the probability that the variable falls within that range. The PDF itself is not a probability but a density, and its total area under the curve equals 1. PDFs help model and analyze the behavior of random variables in probability and statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KA7XxaoeutC"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **Probability Distribution Function (PDF)** describes the likelihood of a random variable taking specific values—exact values for discrete variables (PMF) or density over intervals for continuous variables. It shows how probabilities are distributed.\n",
    "\n",
    "A **Cumulative Distribution Function (CDF)**, on the other hand, gives the probability that the random variable is less than or equal to a certain value. It accumulates probabilities up to that point.\n",
    "\n",
    "In short, the PDF shows the probability at a value or density, while the CDF shows the total probability up to that value, always increasing from 0 to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is a discrete uniform distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ5kKaGCe88j"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **discrete uniform distribution** is a probability distribution where a finite number of outcomes are equally likely. Each possible value has the same probability of occurring. For example, rolling a fair six-sided die follows a discrete uniform distribution because each face (1 to 6) has an equal chance of 1/6. The distribution is defined by the set of equally spaced values and assigns each a probability of $\\frac{1}{n}$, where $n$ is the total number of outcomes. It’s often used to model fair games or random selection with equal chances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What are the key properties of a Bernoulli distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrUvoRrFfLRc"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The key properties of a **Bernoulli distribution** are:\n",
    "\n",
    "1. **Two possible outcomes:** Usually labeled as 1 (success) and 0 (failure).\n",
    "2. **Single trial:** It models the outcome of a single experiment or trial.\n",
    "3. **Probability parameter $p$:** The probability of success (1) is $p$, and failure (0) is $1 - p$, where $0 \\leq p \\leq 1$.\n",
    "4. **Mean:** The expected value is $E[X] = p$.\n",
    "5. **Variance:** The variance is $Var(X) = p(1 - p)$.\n",
    "6. **Discrete distribution:** Values are only 0 or 1 with corresponding probabilities.\n",
    "\n",
    "It’s the simplest discrete distribution used to model yes/no or true/false outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. What is the binomial distribution, and how is it used in probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0ce5hMZfV5H"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The **binomial distribution** models the number of successes in a fixed number of independent trials, each with the same probability of success $p$. It describes situations like flipping a coin $n$ times and counting how many heads appear.\n",
    "\n",
    "The probability of getting exactly $k$ successes in $n$ trials is given by:\n",
    "\n",
    "\n",
    "**P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}**\n",
    "\n",
    "\n",
    "It’s widely used to calculate probabilities of outcomes in repeated experiments with two possible outcomes (success/failure), such as quality testing or survey responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What is the Poisson distribution and where is it applied?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKyqTBJ-flcx"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The **Poisson distribution** models the probability of a given number of events happening in a fixed interval of time or space, assuming the events occur independently and at a constant average rate $\\lambda$.\n",
    "\n",
    "Its probability mass function is:\n",
    "\n",
    "\n",
    "**P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}**\n",
    "\n",
    "\n",
    "It’s commonly used to model rare events, like the number of calls received by a call center per hour, traffic accidents at an intersection, or decay events from a radioactive source.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. What is a continuous uniform distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxgqJNRhf5gn"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **continuous uniform distribution** is a probability distribution where all values within a specified interval $[a, b]$ are equally likely. The probability density function (PDF) is constant between $a$ and $b$, and zero outside this range. The PDF is:\n",
    "\n",
    "\n",
    "**f(x) = \\frac{1}{b - a} \\quad \\text{for } a \\leq x \\leq b**\n",
    "\n",
    "\n",
    "and zero elsewhere. This distribution models situations where every outcome in the interval has the same chance, like choosing a random number between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. What are the characteristics of a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN07krmNgI0f"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The key characteristics of a **normal distribution** are:\n",
    "\n",
    "1. **Bell-shaped curve:** Symmetrical and centered around the mean.\n",
    "2. **Defined by mean (μ) and standard deviation (σ):** Mean determines the center; σ controls the spread.\n",
    "3. **Symmetry:** Equal probability on both sides of the mean.\n",
    "4. **68-95-99.7 rule:** About 68% data within 1σ, 95% within 2σ, and 99.7% within 3σ.\n",
    "5. **Continuous and smooth:** Values range from $-\\infty$ to $+\\infty$.\n",
    "6. **Mathematically described by the PDF:**\n",
    "\n",
    "\n",
    "**f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }**\n",
    "\n",
    "\n",
    "It’s widely used due to the Central Limit Theorem and natural phenomena fitting this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. What is the standard normal distribution, and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVZdQLsxgZhe"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The **standard normal distribution** is a special case of the normal distribution with a mean ($\\mu$) of 0 and a standard deviation ($\\sigma$) of 1. Its probability density function (PDF) is:\n",
    "\n",
    "\n",
    "**f(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}}**\n",
    "\n",
    "\n",
    "where **'z'** represents standardized values called **z-scores**.\n",
    "\n",
    "It’s important because it allows comparison of different normal distributions by converting values to the standard scale. This standardization simplifies probability calculations and hypothesis testing using z-tables. It’s fundamental in statistics for interpreting data and applying the Central Limit Theorem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHAZZr9dgqZy"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The **Central Limit Theorem (CLT)** states that the sum or average of a large number of independent, identically distributed random variables, regardless of their original distribution, will approximate a normal distribution as the sample size grows.\n",
    "\n",
    "This is critical because it justifies using normal distribution techniques for inference, even when the underlying data isn’t normal. It enables confidence intervals, hypothesis testing, and many statistical methods to work reliably with real-world data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. How does the Central Limit Theorem relate to the normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miUri-p8g5dL"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The **Central Limit Theorem (CLT)** explains that as you take larger samples from any population (with finite mean and variance), the distribution of the sample means approaches a **normal distribution**, regardless of the original data’s shape. This means even if the underlying data is skewed or irregular, the averages of sufficiently large samples will be normally distributed. This relationship allows statisticians to use normal distribution tools for inference, making the CLT fundamental in statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. What is the application of Z statistics in hypothesis testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G_81yORhDP4"
   },
   "source": [
    "\n",
    "\n",
    "Ans: **Z statistics** are used in hypothesis testing to determine how far a sample mean is from the population mean, measured in standard errors. By calculating a **Z-score**, you can assess the likelihood of observing the sample data if the null hypothesis is true. If the Z-score falls in the critical region (beyond a threshold), you reject the null hypothesis. Z-tests are commonly applied when the population variance is known or the sample size is large, helping decide if differences are statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. How do you calculate a Z-score, and what does it represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQgsm6zMhNEj"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **Z-score** is calculated using the formula:\n",
    "\n",
    "\n",
    "##### **Z = \\frac{X - \\mu}{\\sigma}**\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "* **X** = the value being standardized\n",
    "* **\\mu** = the mean of the population\n",
    "* **\\sigma** = the standard deviation of the population\n",
    "\n",
    "The Z-score represents how many standard deviations $X$ is away from the mean. A positive Z-score means **X** is above the mean, and a negative Z-score means it’s below. It’s used to standardize values for comparison and probability calculations in a normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. What are point estimates and interval estimates in statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I-RpEyDhtZc"
   },
   "source": [
    "\n",
    "\n",
    "Ans: **Point estimates** are single value summaries of a population parameter, like the sample mean used to estimate the population mean. They provide a specific guess but don’t indicate uncertainty.\n",
    "\n",
    "**Interval estimates** give a range of values, called a confidence interval, likely to contain the true population parameter. This range accounts for sampling variability and uncertainty, providing more information about the estimate’s reliability. For example, a 95% confidence interval means there’s a 95% chance the interval includes the true parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. What is the significance of confidence intervals in statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_eL0BXPh7JV"
   },
   "source": [
    "\n",
    "\n",
    "Ans: **Confidence intervals (CIs)** provide a range of plausible values for an unknown population parameter, reflecting the estimate’s uncertainty. They are significant because they:\n",
    "\n",
    "1. **Express precision:** Wider intervals indicate less precision; narrower ones show more confidence in the estimate.\n",
    "2. **Quantify uncertainty:** Unlike point estimates, CIs show variability due to sampling.\n",
    "3. **Support decision-making:** They help determine if effects or differences are statistically meaningful.\n",
    "4. **Indicate reliability:** A 95% CI means if the experiment were repeated many times, 95% of such intervals would contain the true parameter.\n",
    "\n",
    "CIs give a more complete picture than just a single estimate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. What is the relationship between a Z-score and a confidence interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf6HtFttiJi2"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **Z-score** determines the number of standard deviations corresponding to a desired confidence level in a **confidence interval (CI)**. When constructing a CI for a population mean (with known variance), the formula is:\n",
    "\n",
    "\n",
    "##### **\\text{CI} = \\bar{x} \\pm Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}**\n",
    "\n",
    "\n",
    "Here, **Z_{\\alpha/2}** is the Z-score that cuts off the upper **\\alpha/2** tail of the standard normal distribution, reflecting the chosen confidence level (e.g., 1.96 for 95% CI).\n",
    "\n",
    "So, the Z-score defines how wide the confidence interval is, linking probability with the range of plausible parameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. How are Z-scores used to compare different distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRXB0iu0ifli"
   },
   "source": [
    "\n",
    "\n",
    "Ans: Z-scores standardize values from different distributions by converting them into a common scale with mean 0 and standard deviation 1. This allows you to compare scores from different datasets or units directly. For example, a Z-score of 2 means the value is 2 standard deviations above its distribution’s mean, whether it’s test scores, heights, or any other measurement. By using Z-scores, you can determine which value is relatively higher or lower across different distributions, enabling fair comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. What are the assumptions for applying the Central Limit Theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TRnpaMrirF_"
   },
   "source": [
    "\n",
    "\n",
    "Ans: The main assumptions for applying the **Central Limit Theorem (CLT)** are:\n",
    "\n",
    "1. **Independence:** The sampled observations must be independent of each other.\n",
    "2. **Identically distributed:** Each observation comes from the same distribution with the same mean and variance.\n",
    "3. **Finite mean and variance:** The population should have a finite mean and variance.\n",
    "4. **Sample size:** A sufficiently large sample size is required; often $n \\geq 30$ is considered adequate for many distributions. For populations already normal, even small samples work.\n",
    "\n",
    "These conditions ensure that the distribution of the sample mean approaches normality as sample size grows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. What is the concept of expected value in a probability distribution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5CaPH1Qi3lL"
   },
   "source": [
    "\n",
    "Ans: The **expected value** of a probability distribution is the long-run average or mean value you expect from a random variable after many repetitions of an experiment. It’s calculated as the weighted average of all possible outcomes, where each outcome is multiplied by its probability.\n",
    "\n",
    "For a discrete random variable **X**:\n",
    "\n",
    "\n",
    "##### **E(X) = \\sum x_i \\cdot P(x_i)**\n",
    "\n",
    "\n",
    "For a continuous random variable:\n",
    "\n",
    "\n",
    "##### **E(X) = \\int x \\cdot f(x) \\, dx**\n",
    "\n",
    "\n",
    "The expected value represents the center or balance point of the distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. How does a probability distribution relate to the expected outcome of a random variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJIlFxcPjNfK"
   },
   "source": [
    "\n",
    "\n",
    "Ans: A **probability distribution** describes the likelihood of all possible outcomes of a **random variable**. The **expected outcome**—or **expected value**—is the average result you’d anticipate over many repetitions of the experiment, based on that distribution.\n",
    "\n",
    "The expected value is calculated by weighting each outcome by its probability:\n",
    "\n",
    "* **Discrete:**  **E(X) = \\sum x_i \\cdot P(x_i)**\n",
    "* **Continuous:** **E(X) = \\int x \\cdot f(x) \\, dx**\n",
    "\n",
    "Thus, the probability distribution provides the necessary probabilities to compute the expected value, linking it directly to the long-term average behavior of the random variable.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
